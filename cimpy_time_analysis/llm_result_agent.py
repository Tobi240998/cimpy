from langchain_core.messages import HumanMessage, SystemMessage
from langchain_llm import get_llm


class LLM_resultAgent:
    """
    Agent to interpret PowerFactory results into natural language.
    """

    def __init__(self):
        # LLM zentral beziehen
        self.llm = get_llm()

        self.system_prompt = (
            "Du bist Experte f체r elektrische Netze.\n"
            "Fasse technische Spannungs채nderungen, die aufgrund der neuen Lastsituation entstehen, verst채ndlich zusammen, "
            "hebe kritische Werte hervor, gib Warnungen und Empfehlungen, falls sinnvoll. "
            "Gib keine allgemeinen Informationen zur체ck, rein auf die konkrete Simulation bezogene Informationen."
        )

    def summarize(self, results, user_input):
        human_prompt = (
            f"Nutzerfrage: {user_input}\n"
            f"Auswertung: {results}\n"
            "Antworte kurz, technisch korrekt, ohne Wiederholungen."
        )

        

        chat_messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=human_prompt)
        ]

        response = self.llm.invoke(chat_messages)
        return response.content
